{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Set Proxy ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Proxy: http://127.0.0.1:7890\n",
      "HTTPS Proxy: http://127.0.0.1:7890\n",
      "All Proxy: socks5://127.0.0.1:7890\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 设置 HTTP 代理\n",
    "os.environ['http_proxy'] = \"http://127.0.0.1:7890\"\n",
    "os.environ['https_proxy'] = \"http://127.0.0.1:7890\"\n",
    "os.environ['all_proxy'] = \"socks5://127.0.0.1:7890\"\n",
    "\n",
    "# 确认代理已设置\n",
    "print(\"HTTP Proxy:\", os.environ.get('http_proxy'))\n",
    "print(\"HTTPS Proxy:\", os.environ.get('https_proxy'))\n",
    "print(\"All Proxy:\", os.environ.get('all_proxy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Story Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explore the enchanted forest. Armed with nothing but his wits and a tiny, shining acorn, he ventured deeper, drawn by whispers of a hidden treasure. Along the way, Benjamin befriended a wise old owl, who became his guide and protector, revealing secrets that would change their lives forever.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Create an OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the system prompt to set the model's behavior\n",
    "prompt_system = \"You are a helpful assistant whose goal is to help write stories.\"\n",
    "\n",
    "# Define the user prompt to guide specific content generation\n",
    "prompt = \"\"\"Continue the following story. Write no more than 50 words.\n",
    "Once upon a time, in a world where animals could speak, a courageous mouse named Benjamin decided to\"\"\"\n",
    "\n",
    "# Call the ChatCompletion API to generate a response\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # Model to use\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_system},  # System prompt\n",
    "        {\"role\": \"user\", \"content\": prompt}            # User prompt\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response from the model\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Product Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indulge in the elegance of our handcrafted, limited-edition fountain pen, meticulously crafted from rich rosewood and adorned with gleaming gold accents. Each pen is a masterpiece, offering a smooth writing experience that elevates every word. Embrace the art of writing with this exquisite fusion of luxury and craftsmanship.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Create an OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the system prompt to set the model's behavior\n",
    "prompt_system = \"\"\"You are a helpful assistant whose goal is to help write product descriptions.\"\"\"\n",
    "\n",
    "# Define the user prompt to guide specific content generation\n",
    "prompt = \"\"\"Write a captivating product description for a luxurious, handcrafted, limited-edition fountain pen made from rosewood and gold. Write no more than 50 words.\"\"\"\n",
    "\n",
    "# Call the ChatCompletion API to generate a response\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_system},  # System prompt\n",
    "        {\"role\": \"user\", \"content\": prompt}            # User prompt\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response from the model\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden rays kiss the meadow fair,  \n",
      "Butterflies dance in the warm, sweet air.  \n",
      "Laughter echoes by the shimmering sea,  \n",
      "Summer whispers, \"Come, be free.\"  \n",
      "\n",
      "Lavender blooms and the soft breeze sighs,  \n",
      "Children's giggles, bright painted skies.  \n",
      "Fireflies twinkle as day turns to night,  \n",
      "In summer's embrace, the world feels right.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Create an OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the system prompt to set the model's behavior\n",
    "prompt_system = \"You are a helpful assistant whose goal is to write short poems.\"\n",
    "\n",
    "# Define the user prompt template for generating a poem on a given topic\n",
    "prompt = \"\"\"Write a short poem about {topic}.\"\"\"\n",
    "\n",
    "# Call the ChatCompletion API to generate a response\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_system},  # System prompt\n",
    "        {\"role\": \"user\", \"content\": prompt.format(topic=\"summer\")}  # User prompt with topic set to \"summer\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response from the model\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-Context Learning And Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden sun above,  \n",
      "Fields of green and skies so blue,  \n",
      "Nature's warm embrace.  \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Create an OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define the system prompt to set the model's behavior\n",
    "prompt_system = \"You are a helpful assistant whose goal is to write short poems.\"\n",
    "\n",
    "# Define the user prompt template for generating a poem on a given topic\n",
    "prompt = \"\"\"Write a short poem about {topic}.\"\"\"\n",
    "\n",
    "# Define example poems for specific topics\n",
    "examples = {\n",
    "    \"nature\": \"\"\"Birdsong fills the air,\n",
    "Mountains high and valleys deep,\n",
    "Nature's music sweet.\"\"\",\n",
    "    \"winter\": \"\"\"Snow blankets the ground,\n",
    "Silence is the only sound,\n",
    "Winter's beauty found.\"\"\"\n",
    "}\n",
    "\n",
    "# Call the ChatCompletion API to generate a response\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt_system},  # System prompt\n",
    "        {\"role\": \"user\", \"content\": prompt.format(topic=\"nature\")},  # User prompt with \"nature\" topic\n",
    "        {\"role\": \"assistant\", \"content\": examples[\"nature\"]},       # Assistant's response example for \"nature\"\n",
    "        {\"role\": \"user\", \"content\": prompt.format(topic=\"winter\")},  # User prompt with \"winter\" topic\n",
    "        {\"role\": \"assistant\", \"content\": examples[\"winter\"]},       # Assistant's response example for \"winter\"\n",
    "        {\"role\": \"user\", \"content\": prompt.format(topic=\"summer\")}   # New user prompt with \"summer\" topic\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the generated response from the model\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-Shot Prompting Example (USE LangChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: purple\n",
      "Emotion: creativity\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM with specific parameters\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Define examples of colors and their associated emotions\n",
    "examples = [\n",
    "    {\"color\": \"red\", \"emotion\": \"passion\"},\n",
    "    {\"color\": \"blue\", \"emotion\": \"serenity\"},\n",
    "    {\"color\": \"green\", \"emotion\": \"tranquility\"},\n",
    "]\n",
    "\n",
    "# Template for formatting each example\n",
    "example_formatter_template = \"\"\"\n",
    "Color: {color}\n",
    "Emotion: {emotion}\\n\n",
    "\"\"\"\n",
    "\n",
    "# Define the example prompt template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"color\", \"emotion\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "# Define the FewShotPromptTemplate with examples and input prompts\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"\"\"Here are some examples of colors and the emotions associated with them:\\n\\n\"\"\",\n",
    "    suffix=\"\"\"\\n\\nNow, given a new color, identify the emotion associated with it:\\nColor: {input}\\nEmotion:\"\"\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n\",\n",
    ")\n",
    "\n",
    "# Format the final prompt with the input color \"purple\"\n",
    "formatted_prompt = few_shot_prompt.format(input=\"purple\")\n",
    "\n",
    "# Create the LLMChain for generating responses\n",
    "chain = LLMChain(llm=llm, prompt=PromptTemplate(template=formatted_prompt, input_variables=[]))\n",
    "\n",
    "# Run the chain to get the AI-generated emotion associated with the input color\n",
    "response = chain.run({})\n",
    "\n",
    "# Output the result\n",
    "print(\"Color: purple\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Role Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theme: interstellar travel\n",
      "Year: 3030\n",
      "AI-generated song title: \"Galactic Odyssey: Echoes of 3030\"\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Define the template for the song title prompt\n",
    "template = \"\"\"\n",
    "As a futuristic robot band conductor, I need you to help me come up with a song title.\n",
    "What's a cool song title for a song about {theme} in the year {year}?\n",
    "\"\"\"\n",
    "\n",
    "# Create a PromptTemplate with theme and year as input variables\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"theme\", \"year\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# Create the LLMChain with the specified prompt and LLM\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Input data for the prompt, with theme and year specified\n",
    "input_data = {\"theme\": \"interstellar travel\", \"year\": \"3030\"}\n",
    "\n",
    "# Run the chain to generate a song title based on the input data\n",
    "response = chain.run(input_data)\n",
    "\n",
    "# Output the theme, year, and AI-generated song title\n",
    "print(\"Theme: interstellar travel\")\n",
    "print(\"Year: 3030\")\n",
    "print(\"AI-generated song title:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: Albert Einstein's theory of general relativity, published in 1915, revolutionized our understanding of gravity. It posits that gravity is not a force in the traditional sense but rather a curvature of spacetime caused by the presence of mass. According to this theory, massive objects like planets and stars warp the fabric of spacetime around them, causing other objects to follow curved paths, which we perceive as gravitational attraction. This framework explains various phenomena, such as the bending of light around massive bodies (gravitational lensing) and the precise orbits of planets. General relativity has been confirmed through numerous experiments and observations, profoundly influencing modern physics and cosmology.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Prompt 1: Question about the scientist's name\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer with only the name, without any additional information.\n",
    "Answer: \"\"\" # Note that we have restricted the output here.\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2: Description of the scientist's theory\n",
    "template_fact = \"\"\"Provide a brief description of {scientist}'s theory of general relativity.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain of Thought Output:\n",
      " To solve the problem, we will analyze each clue step-by-step and determine the seating arrangement of Alice, Bob, Carol, Dave, and Eve.\n",
      "\n",
      "### Step 1: Identify Fixed Positions\n",
      "We have the following clues:\n",
      "1. Alice is sitting somewhere to the left of Bob.\n",
      "2. Carol is not sitting next to Eve.\n",
      "3. Dave is sitting immediately to the right of Alice.\n",
      "4. Bob is not sitting at either end of the row.\n",
      "\n",
      "From clue 4, we know that Bob cannot be in positions 1 or 5. Therefore, Bob can only be in positions 2, 3, or 4.\n",
      "\n",
      "### Step 2: Analyze the Pair of Alice and Dave\n",
      "From clue 3, since Dave is immediately to the right of Alice, we can represent Alice and Dave as a pair (A, D). This means if Alice is in position X, Dave must be in position X+1. \n",
      "\n",
      "The possible pairs (A, D) based on the available positions are:\n",
      "- If Alice is in position 1, Dave is in position 2.\n",
      "- If Alice is in position 2, Dave is in position 3.\n",
      "- If Alice is in position 3, Dave is in position 4.\n",
      "\n",
      "However, if Alice is in position 1, then Bob must be in position 2 or 3, which contradicts clue 4 (Bob cannot be at either end). Therefore, Alice cannot be in position 1.\n",
      "\n",
      "### Step 3: Place Bob\n",
      "Now we consider the remaining pairs:\n",
      "- If Alice is in position 2, Dave is in position 3. This means Bob can only be in position 4 (since he cannot be in position 1 or 5). This arrangement would look like:\n",
      "  - 1: ?\n",
      "  - 2: A\n",
      "  - 3: D\n",
      "  - 4: B\n",
      "  - 5: ?\n",
      "\n",
      "- If Alice is in position 3, Dave is in position 4. This means Bob can only be in position 2. This arrangement would look like:\n",
      "  - 1: ?\n",
      "  - 2: B\n",
      "  - 3: A\n",
      "  - 4: D\n",
      "  - 5: ?\n",
      "\n",
      "### Step 4: Check the Validity of Each Arrangement\n",
      "1. **Arrangement 1** (A in 2, D in 3, B in 4):\n",
      "   - 1: ?\n",
      "   - 2: A\n",
      "   - 3: D\n",
      "   - 4: B\n",
      "   - 5: ?\n",
      "   - Here, Carol and Eve must occupy positions 1 and 5. However, we need to check if Carol is next to Eve. If we place Carol in position 1 and Eve in position 5, they are not next to each other, which satisfies clue 2.\n",
      "\n",
      "2. **Arrangement 2** (A in 3, D in 4, B in 2):\n",
      "   - 1: ?\n",
      "   - 2: B\n",
      "   - 3: A\n",
      "   - 4: D\n",
      "   - 5: ?\n",
      "   - Here, Carol and Eve must occupy positions 1 and 5. If we place Carol in position 1 and Eve in position 5, they are not next to each other, which satisfies clue 2. However, this arrangement violates clue 1 because Alice is not to the left of Bob.\n",
      "\n",
      "### Conclusion\n",
      "The only valid arrangement is:\n",
      "- 1: Carol\n",
      "- 2: Alice\n",
      "- 3: Dave\n",
      "- 4: Bob\n",
      "- 5: Eve\n",
      "\n",
      "Thus, the final order of the friends sitting in a row is:\n",
      "**Carol, Alice, Dave, Bob, Eve.**\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Define the Chain of Thought Prompting template\n",
    "template = \"\"\"\n",
    "You are a logical assistant skilled in solving complex puzzles by analyzing each clue step-by-step.\n",
    "Please solve the following problem by explaining your thought process in detail.\n",
    "\n",
    "Problem: There are five friends — Alice, Bob, Carol, Dave, and Eve — sitting in a row. We know the following:\n",
    "1. Alice is sitting somewhere to the left of Bob.\n",
    "2. Carol is not sitting next to Eve.\n",
    "3. Dave is sitting immediately to the right of Alice.\n",
    "4. Bob is not sitting at either end of the row.\n",
    "\n",
    "Determine the order in which the friends are sitting.\n",
    "\n",
    "Steps:\n",
    "1. Start by identifying any fixed positions based on the clues.\n",
    "2. Use the information that Dave is immediately to the right of Alice to find possible pairs.\n",
    "3. Place Bob according to the rule that he is not at the ends and that Alice is to his left.\n",
    "4. Use the constraint that Carol is not next to Eve to finalize their positions.\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create the PromptTemplate with no additional input variables\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[],  # No external input is required for this prompt\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# Create the LLMChain to connect the prompt and model\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain to get the AI's response following the Chain of Thought reasoning\n",
    "response = chain.run({})\n",
    "\n",
    "# Print the model's step-by-step reasoning and final answer\n",
    "print(\"Chain of Thought Output:\\n\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad Prompt Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dogs, often referred to as \"man's best friend,\" are domesticated mammals that belong to the Canidae family. They are descendants of wolves and have been companions to humans for thousands of years. Dogs are known for their loyalty, intelligence, and ability to form strong bonds with humans. \n",
      "\n",
      "There are hundreds of dog breeds, each with distinct characteristics, sizes, and temperaments. Breeds can range from small, toy-sized dogs like Chihuahuas to large breeds like Great Danes. Dogs are highly social animals and thrive on interaction with people and other animals. \n",
      "\n",
      "They are also known for their keen senses, especially their sense of smell, which is significantly more acute than that of humans. This ability makes them excellent working animals in roles such as search and rescue, therapy, and assistance for people with disabilities.\n",
      "\n",
      "In addition to being pets, dogs play important roles in various fields, including law enforcement, military, and service roles. Their versatility, loyalty, and companionship make them beloved members of many households around the world.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "template = \"Tell me something about {topic}.\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "prompt.format(topic=\"dogs\")\n",
    "\n",
    "# Generate a response from the model\n",
    "response = LLMChain(llm=llm, prompt=prompt).run({\"topic\": \"dogs\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist: Albert Einstein\n",
      "Fact: Albert Einstein was offered the presidency of Israel in 1952, but he declined, stating that he lacked the necessary experience and had no aptitude for dealing with people.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Prompt 1: Question about the scientist\n",
    "template_question = \"\"\"What is the name of the famous scientist who developed the theory of general relativity?\n",
    "Answer with only the name, without any additional information.\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2: Request for interesting facts about the scientist\n",
    "template_fact = \"\"\"Tell me something interesting about {scientist}.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"scientist\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Extract the scientist's name from the response\n",
    "scientist = response_question.strip()\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"scientist\": scientist}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Scientist:\", scientist)\n",
    "print(\"Fact:\", response_fact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres: jazz pop rock\n",
      "Fact: Jazz, pop, and rock are three distinct musical genres that each have their own unique characteristics and cultural significance. Jazz is often characterized by its improvisational nature and complex harmonies, allowing for expressive individual performances. Pop music tends to focus on catchy melodies and widespread appeal, often reflecting contemporary trends and themes. Rock music is known for its strong rhythms and emphasis on electric instruments, often conveying powerful emotions and social messages. Each genre has evolved over time, influencing and intersecting with one another, contributing to the rich tapestry of modern music.\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Prompt 1: Question about musical genres\n",
    "template_question = \"\"\"What are some musical genres?\n",
    "Answer: \"\"\"\n",
    "prompt_question = PromptTemplate(template=template_question, input_variables=[])\n",
    "\n",
    "# Prompt 2: Request for information on specific genres\n",
    "template_fact = \"\"\"Tell me something about {genre1}, {genre2}, and {genre3} without giving any specific details.\n",
    "Answer: \"\"\"\n",
    "prompt_fact = PromptTemplate(input_variables=[\"genre1\", \"genre2\", \"genre3\"], template=template_fact)\n",
    "\n",
    "# Create the LLMChain for the first prompt\n",
    "chain_question = LLMChain(llm=llm, prompt=prompt_question)\n",
    "\n",
    "# Run the LLMChain for the first prompt with an empty dictionary\n",
    "response_question = chain_question.run({})\n",
    "\n",
    "# Assign three hardcoded genres\n",
    "genre1, genre2, genre3 = \"jazz\", \"pop\", \"rock\"\n",
    "\n",
    "# Create the LLMChain for the second prompt\n",
    "chain_fact = LLMChain(llm=llm, prompt=prompt_fact)\n",
    "\n",
    "# Input data for the second prompt\n",
    "input_data = {\"genre1\": genre1, \"genre2\": genre2, \"genre3\": genre3}\n",
    "\n",
    "# Run the LLMChain for the second prompt\n",
    "response_fact = chain_fact.run(input_data)\n",
    "\n",
    "print(\"Genres:\", genre1, genre2, genre3)\n",
    "print(\"Fact:\", response_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips for Effective Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Query: What are some tips for improving communication skills?\n",
      "AI Response: Practice active listening, be clear and concise in your messages, and seek feedback to refine your approach. Engaging in conversations with diverse individuals can also enhance your adaptability and understanding.\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate, PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Define example conversations\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"What's the secret to happiness?\",\n",
    "        \"answer\": \"\"\"Finding balance in life and learning to enjoy the small moments.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How can I become more productive?\",\n",
    "        \"answer\": \"\"\"Try prioritizing tasks, setting goals, and maintaining a healthy work-life balance.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Template for formatting examples\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# Define prefix and suffix for the few-shot prompt\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI life coach. The assistant provides insightful and practical advice to the users' questions. Here are some examples:\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# Create the FewShotPromptTemplate\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create the LLMChain for the few-shot prompt template\n",
    "chain = LLMChain(llm=llm, prompt=few_shot_prompt_template)\n",
    "\n",
    "# Define the user query\n",
    "user_query = \"What are some tips for improving communication skills?\"\n",
    "\n",
    "# Run the LLMChain for the user query\n",
    "response = chain.run({\"query\": user_query})\n",
    "\n",
    "print(\"User Query:\", user_query)\n",
    "print(\"AI Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
